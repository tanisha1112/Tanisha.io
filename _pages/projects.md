---
layout: single
permalink: /projects/
author_profile: false
sidebar:
  nav: "projects"
toc: true
toc_label: "Table of Contents"
toc_icon: "bookmark"

date: 2023-09-09
---

<html>
<head>
    <style>
        body {
            font-family: 'Times New Roman', Times, serif;
        }
    </style>
</head>
<body>

<div style="margin-bottom:1cm; font-family: 'Courier New', Courier, monospace;" align="center"><font size="6">Course Projects</font></div>

</body>
</html>

## Machine Learning

### Explainable AI for Deepfake Detection 


[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/tanisha1112/deepfake-detection)

<img src="https://raw.githubusercontent.com/tanisha1112/tanisha1112.github.io/master/images/XAI.png" width="580">{: .align-center}

The objective of this project was to incorporate explainable AI (XAI) techniques to gain insights into the interpretability of the model. The project utilizes state-of-the-art XceptionNet architecture to detect deepfakes, and then employs LIME and GradCam algorithms to visualize and analyze how the model interprets the results.

We extracted frames from FaceForensics ++ and CelebDF video dataset and trained the Xceptionet model pretrained on ImageNet weights and were able to achieve an accuracy of 0.99. 

### Terrain Identification from Time Series Data

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/tanisha1112/Laplacian-Blob-Detector)

This is a classification task to find different terrains from time series data. The idea is to train a neural network using given data to classify which terrain an unknown data represents. Class label 0 represents "standing/walking" 1 represents "going downstairs" 2 : "going upstairs" And 3: "walking on grass". We use F1 macro score as the evaluation metric.

The repository contains 3 Jupyter notebooks: NN_C1.ipynb, NN_C2.ipynb and NN_C3.ipynb.

* NN_C1 runs a random forest model for predictions
* NN_C2 uses 2 1D CNN model
* NN_C3 uses a BiLSTM model.
## Computer Vision

### Laplacian Blob Detector

[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1NMMu_QHn9m9T8cqx4lot8xK20abHmVwu#scrollTo=8krtvYmqjfLc)      [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/tanisha1112/Laplacian-Blob-Detector)

<img src="https://raw.githubusercontent.com/tanisha1112/tanisha1112.github.io/master/images/blob.png" width="500">{: .align-center}

The idea of a Laplacian blob detector is to convolve the image with a “blob filter” at multiple scales and look for extrema of filter response in the resulting scale space.

Blob Filter:

This filter generated by double derivating Gaussian filter along x and y-axis and adding them. Above is also known as Laplacian of Gaussian.
The Laplace is the sum of second derivatives (the trace of the Hessian matrix). An image convolved with the LoG is the same as the Laplacian of an image convolved with a Gaussian:

<img src="https://raw.githubusercontent.com/tanisha1112/tanisha1112.github.io/master/images/log.png" width="400">{: .align-center}


### Comparative Analysis of 3D & 2D CNN for Lung Cancer Nodule Detection

<br> 
<img src="https://raw.githubusercontent.com/tanisha1112/tanisha1112.github.io/master/images/nn_lung.png" width="500">{: .align-center}

Created 2D and 3D CNN VGG-16 models to detect lung cancer with 79% and 91% sensitivity using Luna16 DICOM images.

Conducted data preprocessing for nodule patch extraction, performed voxel coordinate conversion. 
Applied data augmentation techniques to enhance the dataset’s diversity and model robustness

<img src="https://raw.githubusercontent.com/tanisha1112/tanisha1112.github.io/master/images/nn.png" width="300">{: .align-center}

### Implemented 2D FFT in Python from scratch

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/tanisha1112/ECE-558-Project2/tree/main)


1. a.  Wrote a function to implement g= conv2(f, w, pad), where f is an input image (grey, or RGB), w is a 2-D kernel (e.g., 3 × 3 box filter), and pad represents the 4-padding type clip/zero-padding, wrap around, copy edge, and reflect across edge.

    b.  Created a grey image of size 1024x1024 pixels that consists of a unit impulse at the center of the image (512, 512) and zeros elsewhere. Used this image and a kernel (e.g., selected one from (a)) to confirm that the function is indeed performing convolution. 

2. Implementing and testing the 2-D FFT and its inverse using a built-in 1-D FFT algorithm.

## Natural Language Processing

### Modeling Food Web and Forecasting Populations for Endangered Wildlife Species

Collaborated with Endangered Wildlife OU ̈ through Omdena to build an automated data collection & extraction tool.
• Leveraged Beautiful Soup, Google Search API and journal parsing libraries such as pytesseract and tabula for efficient data
extraction from PDFs and web sources.
• Developed a Haystack BERT Question- Answering model integrated with Streamlit and AWS RDS on the backend to track the population of various species over time.

<p float="left">
  <img src="https://raw.githubusercontent.com/tanisha1112/tanisha1112.github.io/master/images/ew.png" width="33%" />
  <img src="https://raw.githubusercontent.com/tanisha1112/tanisha1112.github.io/master/images/ew2.png" width="33%" />
  <img src="https://raw.githubusercontent.com/tanisha1112/tanisha1112.github.io/master/images/ew1.png" width="33%" />
</p>


## Signal Processing
### Kalman Filter Implementation in Matlab


[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/tanisha1112/Kalman-Filter-Simulation/tree/main)

<img src="https://raw.githubusercontent.com/tanisha1112/tanisha1112.github.io/master/images/Kalman.png" width="500">{: .align-center}


Kalman filter estimates the state of a system with incomplete or noisy information.
* It uses the system model and the measurements to estimate the true state of the system and its uncertainty.
* In this project, I implemented a discrete-time, time-invariant Kalman filter as a MATLAB function.
* For the benchmark case I used the Kalman filter to estimate the position and velocity of a moving object based on noisy measurements of its position.
* Kalman filter will be used to make future predictions using past values to correct the estimated state.


### Convergence and Simulation of Random Variables using Matlab


[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/tanisha1112/Kalman-Filter-Simulation/tree/main)

This project involves simulation, transformation and convergence of Random Variables using 
concepts underlined in:
“Understanding Convergence Concepts: A Visual-Minded and Graphical Simulation- Based Approach'


### FFT Implementation in MATLAB

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/tanisha1112/FFT-Implementation-MATLAB/tree/main#fft-implementation-matlab)

For this assignment, I implemented three functions in MATLAB®:


1. myDFT, a brute-force implementation of the DFT,
2. myFFT_139, a decimation-in-time implementation of the FFT, and
3. "butterfly", a decimation-in-time butterfly called by myFFT_139.
A code listing for these functions is provided in the appendix.
